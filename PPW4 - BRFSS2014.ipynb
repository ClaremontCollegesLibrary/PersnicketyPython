{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a284cf18-070c-4f30-a32b-1c2d131e750e",
   "metadata": {},
   "source": [
    "# Behavioral Risk Factor Surveillance System (BRFSS) 2014"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2787db8-1862-4658-82f5-e0b7e6d53d40",
   "metadata": {},
   "source": [
    "## Topics & Techniques Covered:\n",
    "\n",
    "* Extracting text data from a PDF file\n",
    "* Eliminating whitespace from text strings\n",
    "* Using a dictionary to replace numerical data with text-based categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53373993-3952-477d-b951-6965b333eb7b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9546a5c7-d006-4225-aca8-19e3ba071395",
   "metadata": {},
   "source": [
    "The `io` (input/output) library handles \"file objects\" which are representations of files in text, bytes, or raw format. This is a bit of an abstract concept, but essentially it lets you treat streamed data from a website or other source as if it was a file being read from a hard drive. We will be using this library to read in PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b3ff2-4cad-43e5-bd67-de4eeb2e6046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import StringIO, BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fe37e3-a02a-4b26-a39f-b90a85d90d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a96a7c-a28a-43ca-88a9-7f6449c23b6a",
   "metadata": {},
   "source": [
    "The [pdfminer](https://pdfminersix.readthedocs.io/en/latest/) package lets you extract data from PDF documents. It doesn't work perfectly all the time and usually takes some fiddling, but it is a potential tool to *reproducibly* convert tables in PDF documents to tabular data in Python. How usable it is will depend largely on how well-formatted the PDF is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ba3fb-76b3-4e26-8948-05e49e6e7b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe8264-0719-41cd-abc3-c8c00ad432e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text, extract_pages\n",
    "from pdfminer.layout import LTTextLineHorizontal, LTTextBoxHorizontal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87435c75-cac7-433d-abad-f7b70ae1d9ec",
   "metadata": {},
   "source": [
    "## Behavioral Risk Factor Surveillance System (BRFSS) 2014 Survey Codebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c055b383-540c-46a9-9727-a94a2cacfd0d",
   "metadata": {},
   "source": [
    "The Behavioral Risk Factor Surveillance System is a United States public health survey conducted by the Center for Disease Control to assess behavioral health risks in the United States. The data from the CDC website contains a large amount of data, but it's not easily readable because all the fields are coded to numbers rather than containing the actual categories themselves.\n",
    "\n",
    "The categories are kept in a codebook, which serves as a dictionary so users can translate the survey data. However, the fact that the codebook is a PDF document instead of being in a tabular data format like a spreadsheet makes it difficult to read these codes programmatically. \n",
    "\n",
    "This is why tools like `pdfminer.six` are useful; they let you make tables out of data that isn't formatted in a table to begin with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378e5fc-975c-4ebc-b138-a165f75ade73",
   "metadata": {},
   "source": [
    "[FIPS (Federal Information Processing Standard) codes](https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code) are identifiers that have been used by the Census Bureau and other institutions as unique identifiers for U.S. states and territories.\n",
    "\n",
    "Here, they are used in the BRFSS dataset as state identifiers, but without a link between the FIPS code and the state name/postal abbreviation, it's harder to match the data at a glance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4314565-7b91-48e7-aaa5-47b0e57fdff1",
   "metadata": {},
   "source": [
    "### Codebook Download Links:\n",
    "\n",
    "Available here: https://www.cdc.gov/brfss/annual_data/annual_2014.html\n",
    "\n",
    "PLEASE NOTE: The CDC website has been unreliable over the past several weeks; the codebook was unavailable for a few days during that period. It may or may not be available when you access this link.\n",
    "\n",
    "We have uploaded the codebook to our GitHub page, and, as the CDC website may continue to be unreliable, we are downloading the BRFSS2014 dataset via the Open Science Foundation's repository: https://osf.io/n7wm8.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae71c206-492d-48c7-a610-f86c33fe6762",
   "metadata": {},
   "source": [
    "# `requests`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bc8070-55e5-4ec2-a185-4316fcb3494d",
   "metadata": {},
   "source": [
    "We will be using the `requests` module to perform a \"get\" HTML request to the BRFSS resources.\n",
    "\n",
    "For a more extensive tutorial on the `requests` module and on web-scraping, please see the archived \"Practical Python\" workshop materials on the Library's \"[Introduction to Python](https://libguides.libraries.claremont.edu/intro-to-python)\" Research Guide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbdbc70-6f7a-43f8-8134-57e9b3ef484d",
   "metadata": {},
   "source": [
    "First, we use the `requests` module to make an HTML \"Get\" request to pull the PDF data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95744ee3-bfd1-4905-874d-2f3aa2a91e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdf_response = requests.get(\"https://raw.githubusercontent.com/ClaremontCollegesLibrary/PersnicketyPython/refs/heads/main/brfss_2014_codebook.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3d31c-a6cc-42f2-aeb4-7676e496f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_content = pdf_response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d9af5e-e75a-48b5-a4c8-c0b713735ccf",
   "metadata": {},
   "source": [
    "Here are the first two thousand characters of the PDF file, returned as a Python [Bytes object](https://docs.python.org/3/library/stdtypes.html#bytes-objects)\n",
    "\n",
    "Bytes objects display similarly to Python strings (they are formatted like a string, with a \"b\" at the start before the quotes) but they are fundamentally different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63453c-f552-4e86-b615-f425d44eb300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdf_content[0:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e502e-7d08-4d63-a7b1-53228c489315",
   "metadata": {},
   "source": [
    "The `BytesIO` class from the `io` library allows us to read the Bytes object into a chunk of memory so that it behaves like a file. In this case, the \"%PDF-1.6\" header at the start of the Bytes object indicates that the file is a PDF, and `BytesIO` lets us treat it as if it was a PDF file on the drive for purposes of the `extract_text()` function from `pdfminer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47de10-2219-4d61-91aa-4af52b19fdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = BytesIO(pdf_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f003b6-8175-45b7-ba94-ae87302e1f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T17:50:00.002744Z",
     "iopub.status.busy": "2025-02-06T17:49:59.997501Z",
     "iopub.status.idle": "2025-02-06T17:50:00.079201Z",
     "shell.execute_reply": "2025-02-06T17:50:00.073191Z",
     "shell.execute_reply.started": "2025-02-06T17:50:00.002744Z"
    }
   },
   "source": [
    "# pdfminer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fef5f3f-1a1b-4dbe-9730-f8f14bc8c5f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-06T17:50:00.002744Z",
     "iopub.status.busy": "2025-02-06T17:49:59.997501Z",
     "iopub.status.idle": "2025-02-06T17:50:00.079201Z",
     "shell.execute_reply": "2025-02-06T17:50:00.073191Z",
     "shell.execute_reply.started": "2025-02-06T17:50:00.002744Z"
    }
   },
   "source": [
    "## `extract_text()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23224a66-564d-4169-a5bd-1f9358de0df7",
   "metadata": {},
   "source": [
    "At its simplest, pdfminer converts PDF files to plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9a438-c5ed-44d1-8910-8549c6fa806b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = extract_text(pdf)\n",
    "print(text[0:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c037f1-0007-4547-9b8a-485c8d19c76e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T20:59:33.612335Z",
     "iopub.status.busy": "2024-10-21T20:59:33.611360Z",
     "iopub.status.idle": "2024-10-21T20:59:33.627647Z",
     "shell.execute_reply": "2024-10-21T20:59:33.622472Z",
     "shell.execute_reply.started": "2024-10-21T20:59:33.612335Z"
    }
   },
   "source": [
    "## `extract_pages()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5928c8-a197-4d95-ade8-5d92bd06c172",
   "metadata": {},
   "source": [
    "The extract_pages() function segments the text data based on which page it's on... that data may be further segmented by the individual elements in the layout of each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad284703-df44-44b6-92cd-eef295571903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pages = [page for page in extract_pages(pdf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b6470a-02d9-47db-bcec-ab406e95cf1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for page_layout in pages[0:2]:\n",
    "    for element in page_layout:\n",
    "        print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4027f094-5bae-4fc1-91e1-fb86833714e7",
   "metadata": {},
   "source": [
    "## Identifying Elements and Extracting Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e5d9a3-c35c-476e-9b26-598e8506d631",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_text = []\n",
    "\n",
    "\n",
    "for page_layout in extract_pages(pdf):\n",
    "    for element in page_layout:\n",
    "        if isinstance(element, LTTextLineHorizontal) or isinstance(element, LTTextBoxHorizontal):\n",
    "            table_text.append(element.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b9c653-4102-47dd-9d3b-9b8226322806",
   "metadata": {},
   "source": [
    "Once we've identified the length of the tables on each page, we can locate the starting points in the list `table_text` and take segments of that list to use as columns in a DataFrame object.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1cd8b9-885e-4e04-80d9-2de761bdd51b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n=0\n",
    "for line in table_text[0:200]:\n",
    "    print(n, line)\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92027b9-4eca-4fc9-86d1-7caaadfba1d3",
   "metadata": {},
   "source": [
    "The column headers that we're interested in are in cells 19, 20, 93, 94, and 95, and the segments of the data we want to extract start on cells 21, 56, 96, 131, and 166 for the first chunk, respectively. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4154aa05-6cb1-43e5-8273-c557baf9742a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n=200\n",
    "for line in table_text[200:400]:\n",
    "    print(n, line)\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005408b4-fc9f-47af-b3c1-e9561ce4d79d",
   "metadata": {},
   "source": [
    "In the second chunk, the columns start in cells 214, 232, 255, 273, and 291, and the length of each one is 18 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2832a0-23d4-4d70-80a4-fbeea10db599",
   "metadata": {},
   "source": [
    "The column headers will need to be cleaned as well. Fortunately, the pattern is consistent. Every element's text has trailing whitespace and a newline character (`\\n`), so we can use the string method `.replace()` to pare down each string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e91295-44e3-49cf-9f6c-d7da4a5c641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_text[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea2367d-eef7-4d37-b4ad-71d1f3036773",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_text[19].replace(' \\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12d008-b1fa-43c5-9f2c-fdb1db38f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_text[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35722c11-3680-476e-af90-b460f6e4b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_text[21].replace(' \\n','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdc5dfe-4a75-412c-a695-a4bdc95fa6f1",
   "metadata": {},
   "source": [
    "Here we can use multiple list comprehensions to create columns for a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f0de2-0af1-4ce7-b8e3-40c91ea19f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_length = 35\n",
    "table_length2 = 18\n",
    "\n",
    "state_fips = pd.DataFrame()\n",
    "\n",
    "state_fips[table_text[19].replace(' \\n','')] = [\n",
    "    value.replace(' \\n','') for value in table_text[21:21+table_length] + table_text[214:214+table_length2]\n",
    "        ]\n",
    "\n",
    "state_fips[table_text[20].replace(' \\n','')] = [\n",
    "    value.replace(' \\n','') for value in table_text[56:56+table_length] + table_text[232:232+table_length2]\n",
    "        ]\n",
    "\n",
    "state_fips[table_text[93].replace(' \\n','')] = [\n",
    "    value.replace(' \\n','') for value in table_text[96:96+table_length]+ table_text[255:255+table_length2]\n",
    "        ]\n",
    "\n",
    "state_fips[table_text[94].replace(' \\n','')] = [\n",
    "    value.replace(' \\n','') for value in table_text[131:131+table_length] + table_text[273:273+table_length2]\n",
    "        ]\n",
    "\n",
    "state_fips[table_text[95].replace(' \\n','')] = [\n",
    "    value.replace(' \\n','') for value in table_text[166:166+table_length] + table_text[291:291+table_length2]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe882b3-bd8f-4173-ba0d-18071bdf64e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "state_fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880e41f-650c-449d-a056-ad67728c5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_fips = zip(state_fips['Value'].values, state_fips['Value Label'].values)\n",
    "\n",
    "fips_dict = {int(value):label for value, label in zipped_fips}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b9d9a-d256-4e9d-9da7-f3cc598f480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fips_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a53da1-1d0b-46b4-a061-b3196ca73fe9",
   "metadata": {},
   "source": [
    "# Read In BRFSS 2014 data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ce821a-7f49-45e5-a07b-4f60b417706c",
   "metadata": {},
   "source": [
    "Next, we can read in the survey data. A copy of it is hosted by the [Open Science Foundation](https://osf.io/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad0570-3399-4ce0-81fe-1758c381deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "osf = requests.get('https://osf.io/download/n7wm8/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43936259-a053-4a59-ada1-f97e32e7b203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "osf.content[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d6eef-1ecf-478b-93bb-7e37f6554f95",
   "metadata": {},
   "source": [
    "This is a .csv file, encoded using the 'latin-1' encoding. The bytes must be decoded using the correct encoding in order for the data to be accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae0d1c-adb0-4a07-88a5-9b489226ca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "osf.content.decode('latin-1')[0:3000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edea15f3-a49e-4bde-9f0a-89d5734deb2f",
   "metadata": {},
   "source": [
    "To read in the Bytes object as a csv file, we need to use a mechanism called a context manager. This is essentially a way of opening and closing a file all in one sequence, so that system resources aren't left occupied and may be freed up for other processes. In Python, context managers typically take the form of a \"with... as\" statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03385da-0a28-4873-89db-f6746f12588c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use a context manager to read in the bytes as a .csv into pandas:\n",
    "\n",
    "with BytesIO(osf.content) as osf_data:\n",
    "    print(type(osf_data))\n",
    "    df_osf = pd.read_csv(osf_data, encoding='latin-1', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4f1bf-b2c4-4aaa-9dd2-bc81b0448678",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_osf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb194a0-c582-433d-8e17-e54d330a055e",
   "metadata": {},
   "source": [
    "We can now use our dictionary to replace the FIPS codes in the `_state` column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff829ad-cab2-4c3a-9946-a52b94cb550d",
   "metadata": {},
   "source": [
    "# Replace Codes with States Using Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5cb5f-8074-4a5b-9581-dbf006f5ae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_osf['_state'] = df_osf['_state'].apply(lambda x: fips_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b65f80-a72b-4e1d-86b0-d37855bbbcd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_osf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd312b08-623a-49ae-865b-2e5703a2b14b",
   "metadata": {},
   "source": [
    "It's best to double-check the results; if we see any numbers in the `_state` column, we'll know something didn't work right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac8f9af-a5eb-4cb2-b28e-461f810d33b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_osf['_state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40223ce5-a23a-4164-bc82-0d64d02c197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_osf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5126c74f-6178-4192-a20b-dd11bfc70f61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_osf.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46abe406-8884-4819-84b1-2eb8519860d7",
   "metadata": {},
   "source": [
    "As you can see, the other 225 columns each contain a different variable; in order to access these, we could construct tables using `pdfminer` the same way we did for the FIPS codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc8e649-9e47-4293-9fca-8b2e5e228acb",
   "metadata": {},
   "source": [
    "# End of Module 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7337b5c-6ddf-4570-98a4-d30bd8e4a957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
